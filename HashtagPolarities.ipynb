{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hashtag Polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from src.features import generate_features\n",
    "import tweepy\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./config/viz_params.json') as f:\n",
    "    viz_params = json.load(f)\n",
    "\n",
    "# Cfg variables\n",
    "path = viz_params['path']\n",
    "top_k = viz_params['top_k']\n",
    "top_k_fig_path = viz_params['top_k_fig_path']\n",
    "user_hist_path = viz_params['user_hist_path']\n",
    "user_hist_zoom_path = viz_params['user_hist_zoom_path']\n",
    "good_path = viz_params['good_path']\n",
    "bad_path = viz_params['bad_path']\n",
    "good_tags = viz_params['good_tags']\n",
    "bad_tags = viz_params['bad_tags']\n",
    "maximum_posts = viz_params['maximum_posts']\n",
    "api_keys = viz_params['api_keys']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "jsons = [os.path.join(path, name) for name in sorted(os.listdir(path)) if 'dataset' in name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of occurences of every hashtag in the JSON\n",
    "def hashtag_counts(json, misinformation_hashtags):\n",
    "    df = pd.read_json(json, lines = True)\n",
    "    ht = df['entities'].apply(lambda e: [x['text'] for x in e['hashtags']])\n",
    "       \n",
    "    if not misinformation_hashtags is None:\n",
    "        ht = ht.apply(lambda x: x if set(x) & misinformation_hashtags else None).dropna()\n",
    "    return pd.Series(ht.sum()).value_counts(), len(ht)\n",
    "\n",
    "\n",
    "# Count the number of posts every user has made in the JSON\n",
    "def user_counts(json, misinformation_hashtags):\n",
    "    df = pd.read_json(json, lines=True)\n",
    "    us = df['user'].apply(lambda x: x['screen_name'])\n",
    "    return us.value_counts(), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide whether to count hashtags or users\n",
    "def count_features(jsons, misinformation_hashtags = None, top_k = None, mode = 'hashtag'):\n",
    "    # Decide whether to count hashtags or users\n",
    "    if mode == 'hashtag':\n",
    "        method = hashtag_counts\n",
    "    elif mode == 'user':\n",
    "        method = user_counts\n",
    "        \n",
    "    # Compile count of first JSON in list\n",
    "    total_series, tweet_count = method(jsons[0], misinformation_hashtags)\n",
    "    print(f'vc shape {total_series.shape}', end='\\r')\n",
    "    \n",
    "    # Append counts to every subsequent JSON\n",
    "    for json in jsons[1:]:\n",
    "        vc_series, vc_count = method(json, misinformation_hashtags)\n",
    "        total_series = total_series.add(vc_series, fill_value = 0)\n",
    "        tweet_count += vc_count\n",
    "        print(f'vc shape {total_series.shape}', end='\\r')\n",
    "        \n",
    "    # Return the top users/hashtags in all of the data\n",
    "    return total_series.sort_values().sort_values(ascending=False)/tweet_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vc shape (801,)\r"
     ]
    }
   ],
   "source": [
    "marker_rate = count_features(jsons, set([\"WuhanVirus\", \"Hydroxychloroquine\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vc shape (118286,)\r"
     ]
    }
   ],
   "source": [
    "baseline_rate = count_features(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_200 = baseline_rate.iloc[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WuhanVirus            0.528837\n",
       "Hydroxychloroquine    0.486804\n",
       "COVID19               0.186706\n",
       "coronavirus           0.091887\n",
       "ChinaVirus            0.051808\n",
       "                        ...   \n",
       "DragonVirus19         0.000978\n",
       "DrZev                 0.000978\n",
       "DownWithTheCCP        0.000978\n",
       "DE                    0.000978\n",
       "RFI_En                0.000978\n",
       "Length: 801, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "marker_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.DataFrame(top_200)\n",
    "test.columns = [\"baseline\"]\n",
    "full_df = test.join(pd.DataFrame(marker_rate)).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = full_df[0] - full_df[\"baseline\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "polarity = polarity/full_df['baseline']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ecuador             -1.000000\n",
       "Health              -1.000000\n",
       "Video               -1.000000\n",
       "NewYork             -1.000000\n",
       "YoMeQuedoEnCasa     -1.000000\n",
       "                      ...    \n",
       "HongKong            49.401944\n",
       "CCP                124.461046\n",
       "ChineseVirus       212.622862\n",
       "CCPVirus           215.299841\n",
       "ChinaVirus         327.033041\n",
       "Length: 198, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "polarity.sort_values().iloc[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User polarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(api_keys) as f:\n",
    "    keys = json.load(f)\n",
    "\n",
    "    consumer_key = keys['consumer_key']\n",
    "    consumer_secret = keys['consumer_secret']\n",
    "    access_token = keys['access_token']\n",
    "    access_token_secret = keys['access_token_secret']\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_users(jsons):\n",
    "    all_users = set()\n",
    "    for json in jsons:\n",
    "        df = pd.read_json(json, lines=True)\n",
    "        us = set(df['user'].apply(lambda x: x['screen_name']))\n",
    "        all_users = all_users.union(us)\n",
    "        print(len(all_users), end='\\r')\n",
    "    return pd.Series(list(all_users))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "774198\r"
     ]
    }
   ],
   "source": [
    "all_users = get_all_users(jsons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         BoysandGirlsAid\n",
       "1            BuzzDramatic\n",
       "2           SeamasterGMT1\n",
       "3           PalleShravani\n",
       "4                 treyn43\n",
       "               ...       \n",
       "774193        PrettyJaden\n",
       "774194       TreforJones2\n",
       "774195      chukwujekwu90\n",
       "774196           _TheMann\n",
       "774197    umakantsingh_IN\n",
       "Length: 774198, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_user_polarity(x):\n",
    "    tweets = []\n",
    "    page = 1\n",
    "    at_start_date = False\n",
    "    # Get data FROM 3-1-20 TO 10-1-20\n",
    "    try:\n",
    "        while not at_start_date:\n",
    "            new_tweets = api.user_timeline(screen_name=x, page=page)\n",
    "            if not new_tweets:\n",
    "                return None\n",
    "            for tweet in new_tweets:\n",
    "                if datetime.datetime(2020, 10, 1) <= tweet.created_at:\n",
    "                    pass\n",
    "                elif datetime.datetime(2020, 3, 1) > tweet.created_at:\n",
    "                    at_start_date = True\n",
    "                    break\n",
    "                else:\n",
    "                    tweets.append(tweet)\n",
    "            page += 1\n",
    "    except:\n",
    "        return None\n",
    "    \n",
    "    # Get all hashtags\n",
    "    ht = [h['text'] for tweet in tweets for h in tweet._json['entities']['hashtags']]\n",
    "    user_pol = 0\n",
    "    ht_count = 0\n",
    "    \n",
    "    # Add all hashtag polarities\n",
    "    for hashtag in ht:\n",
    "        try:\n",
    "            user_pol += polarity.loc[hashtag]\n",
    "            ht_count += 1\n",
    "        except:\n",
    "            continue\n",
    "    if ht_count == 0:\n",
    "        return None\n",
    "    return user_pol / ht_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/tqdm/std.py:668: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2688/774198 [09:37<5997:28:43, 27.99s/it]"
     ]
    }
   ],
   "source": [
    "user_polarities = all_users.progress_apply(normalized_user_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
